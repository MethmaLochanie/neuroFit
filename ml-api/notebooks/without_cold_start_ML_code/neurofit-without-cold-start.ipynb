{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11199799,"sourceType":"datasetVersion","datasetId":6992705},{"sourceId":11209290,"sourceType":"datasetVersion","datasetId":6999334},{"sourceId":311653,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":264323,"modelId":285415},{"sourceId":319742,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":269795,"modelId":290785}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, glob, math, gc\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, default_collate\nfrom torch_geometric.data import HeteroData\nfrom torch_geometric.utils import sort_edge_index\nfrom sklearn.model_selection import GroupShuffleSplit, GroupKFold\nfrom sklearn.metrics import roc_auc_score\nfrom torchvision import transforms, models\nfrom PIL import Image\nfrom transformers import DistilBertTokenizer, DistilBertModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:25:19.927153Z","iopub.execute_input":"2025-04-03T19:25:19.927443Z","iopub.status.idle":"2025-04-03T19:25:41.321402Z","shell.execute_reply.started":"2025-04-03T19:25:19.927421Z","shell.execute_reply":"2025-04-03T19:25:41.320681Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# --------------------------\n# Configuration\n# --------------------------\nclass Config:\n    text_max_length = 64\n    batch_size = 128\n    emb_dim = 256\n    num_heads = 4\n    dropout = 0.5\n    lr = 5e-5           # Lower learning rate as recommended\n    weight_decay = 1e-5\n    epochs = 2\n    patience = 5        # For early stopping\n    k_folds = 2\n\nconfig = Config()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntorch.backends.cudnn.benchmark = True  # may help on GPU\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:25:46.970861Z","iopub.execute_input":"2025-04-03T19:25:46.971483Z","iopub.status.idle":"2025-04-03T19:25:46.976537Z","shell.execute_reply.started":"2025-04-03T19:25:46.971457Z","shell.execute_reply":"2025-04-03T19:25:46.975532Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# --------------------------\n# 1. Comprehensive Preprocessing\n# --------------------------\ndef load_and_preprocess():\n    articles = pd.read_csv(\"/kaggle/input/h-and-m-personalized-fashion-recommendations/articles.csv\")\n    customers = pd.read_csv(\"/kaggle/input/h-and-m-personalized-fashion-recommendations/customers.csv\")\n    transactions = pd.read_csv(\"/kaggle/input/h-and-m-personalized-fashion-recommendations/transactions_train.csv\")\n    \n    # Adjust IDs\n    def adjust_id(x):\n        x = str(x)\n        return \"0\" + x if len(x) == 9 else x\n    transactions[\"article_id\"] = transactions[\"article_id\"].apply(adjust_id)\n    articles[\"article_id\"] = articles[\"article_id\"].apply(adjust_id)\n    \n    # Filter customers\n    customers = customers[['customer_id', 'age']].dropna(subset=['age'])\n    valid_article_ids = set(articles['article_id'].unique())\n    filtered_transactions = transactions[transactions['article_id'].isin(valid_article_ids)]\n    \n    # Cold-start handling\n    transaction_counts = filtered_transactions['customer_id'].value_counts()\n    frequent_customers = transaction_counts[transaction_counts > 8].index.tolist()\n    cold_start_few = transaction_counts[transaction_counts <= 2].index.tolist()\n    cold_start_no = list(set(customers['customer_id']) - set(filtered_transactions['customer_id']))\n    \n    # Stratified sampling (50-30-20)\n    def sample_customers(group, target_size):\n        return np.random.choice(group, size=min(len(group), target_size), replace=False)\n    sample_sizes = [50000, 30000, 20000]  # total ~100k\n    sampled = [\n        sample_customers(frequent_customers, sample_sizes[0]),\n        sample_customers(cold_start_few, sample_sizes[1]),\n        sample_customers(cold_start_no, sample_sizes[2])\n    ]\n    sampled_customers = np.concatenate(sampled)\n    sampled_customers = customers[customers['customer_id'].isin(sampled_customers)].reset_index(drop=True)\n    sampled_customers = sampled_customers[['customer_id', 'age']]\n    \n    # Filter transactions by sampled customers and valid articles\n    filtered_trans = filtered_transactions[\n        (filtered_transactions['customer_id'].isin(sampled_customers['customer_id'])) &\n        (filtered_transactions['article_id'].isin(valid_article_ids))\n    ]\n    \n    # Get image paths\n    all_image_paths = glob.glob(\"/kaggle/input/h-and-m-personalized-fashion-recommendations/images/*/*.jpg\")\n    valid_ids = set(os.path.splitext(os.path.basename(p))[0] for p in all_image_paths)\n    def get_image_path(aid):\n        subfolder = aid[:3]\n        path = f\"/kaggle/input/h-and-m-personalized-fashion-recommendations/images/{subfolder}/{aid}.jpg\"\n        return path if aid in valid_ids else None\n    articles['image_path'] = articles['article_id'].apply(get_image_path)\n    articles = articles.dropna(subset=['image_path']).reset_index(drop=True)\n    \n    # Merge article prices from transactions\n    article_prices = filtered_trans[['article_id', 'price']].drop_duplicates(subset=['article_id'])\n    articles = articles.merge(article_prices, on='article_id', how='inner')\n    articles['detail_desc'] = articles['detail_desc'].fillna('').astype(str)\n    articles = articles[['article_id', 'detail_desc', 'image_path', 'price']]\n    \n    valid_articles = set(articles['article_id'])\n    filtered_trans = filtered_trans[filtered_trans['article_id'].isin(valid_articles)]\n    \n    # Validate image paths\n    articles['image_exists'] = articles['image_path'].apply(os.path.exists)\n    missing = articles[~articles['image_exists']]\n    if len(missing) > 0:\n        print(f\"Found {len(missing)} articles with missing images. Samples:\")\n        print(missing.sample(min(5, len(missing))))\n        articles = articles[articles['image_exists']].drop(columns=['image_exists'])\n    else:\n        print(\"All images validated successfully!\")\n    \n    # Create mapped IDs\n    articles = articles.reset_index(drop=True)\n    articles[\"article_mapped_id\"] = articles.index\n    sampled_customers = sampled_customers.reset_index(drop=True)\n    sampled_customers[\"customer_mapped_id\"] = sampled_customers.index\n    filtered_trans = filtered_trans.merge(\n        articles[['article_id', 'article_mapped_id']],\n        on='article_id',\n        how='inner'\n    ).merge(\n        sampled_customers[['customer_id', 'customer_mapped_id']],\n        on='customer_id',\n        how='inner'\n    )\n    \n    # --------------------------\n    # Precompute raw features for products\n    # --------------------------\n    # Use a FeatureProcessor instance (defined below) to precompute image and text features.\n    fp = FeatureProcessor()\n    # Precompute image and text features (store as tensors on CPU)\n    img_feats, txt_feats = [], []\n    for idx, row in tqdm(articles.iterrows(), total=len(articles), desc=\"Precomputing product features\"):\n        try:\n            # Image features via a pretrained ResNet18\n            img = Image.open(row['image_path']).convert('RGB')\n            img_tensor = fp.image_transform(img).unsqueeze(0).to(device)\n            img_feat = models.resnet18(pretrained=True).eval().to(device)(img_tensor).squeeze().cpu()\n            img_feats.append(img_feat)\n            \n            # Text features via DistilBERT\n            text = row['detail_desc']\n            text_enc = fp.tokenizer(text, padding='max_length', truncation=True,\n                                    max_length=config.text_max_length, return_tensors='pt').to(device)\n            txt_feat = DistilBertModel.from_pretrained('distilbert-base-uncased').eval().to(device)(**text_enc).last_hidden_state[:,0].squeeze().cpu()\n            txt_feats.append(txt_feat)\n        except Exception as e:\n            print(f\"Error precomputing features for article {row['article_id']}: {e}\")\n            img_feats.append(torch.zeros(1000))\n            txt_feats.append(torch.zeros(768))\n    articles['img_feat'] = img_feats\n    articles['txt_feat'] = txt_feats\n    \n    return sampled_customers, filtered_trans, articles\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:54:01.138259Z","iopub.execute_input":"2025-03-30T15:54:01.138494Z","iopub.status.idle":"2025-03-30T15:54:01.161473Z","shell.execute_reply.started":"2025-03-30T15:54:01.138464Z","shell.execute_reply":"2025-03-30T15:54:01.160657Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# --------------------------\n# 2. Feature Processing\n# --------------------------\nclass FeatureProcessor:\n    def __init__(self):\n        self.image_transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406],\n                                 [0.229, 0.224, 0.225])\n        ])\n        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\n    def process_text(self, texts):\n        return self.tokenizer(texts, padding='max_length', truncation=True,\n                              max_length=config.text_max_length, return_tensors='pt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T15:54:01.162451Z","iopub.execute_input":"2025-03-30T15:54:01.162819Z","iopub.status.idle":"2025-03-30T15:54:01.182598Z","shell.execute_reply.started":"2025-03-30T15:54:01.162787Z","shell.execute_reply":"2025-03-30T15:54:01.181685Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# --------------------------\n# Build a product feature dictionary for fast lookup\n# --------------------------\ndef build_product_feature_dict(articles):\n    prod_dict = {}\n    for idx, row in articles.iterrows():\n        prod_dict[int(row['article_mapped_id'])] = {\n            'img_feat': row['img_feat'], \n            'txt_feat': row['txt_feat'],\n            'price': torch.tensor(row['price'], dtype=torch.float32)\n        }\n    return prod_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:25:56.796074Z","iopub.execute_input":"2025-04-03T19:25:56.796390Z","iopub.status.idle":"2025-04-03T19:25:56.800796Z","shell.execute_reply.started":"2025-04-03T19:25:56.796364Z","shell.execute_reply":"2025-04-03T19:25:56.799920Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# --------------------------\n# 3. Simplified Graph Construction (unchanged)\n# --------------------------\ndef build_graph(transactions, articles, customers):\n    data = HeteroData()\n    data['user'].num_nodes = len(customers)\n    data['product'].num_nodes = len(articles)\n    edge_index = torch.tensor([\n        transactions['customer_mapped_id'].values,\n        transactions['article_mapped_id'].values\n    ], dtype=torch.long)\n    edge_index = sort_edge_index(edge_index)\n    data['user', 'buys', 'product'].edge_index = edge_index\n    data['product', 'rev_buys', 'user'].edge_index = edge_index.flip(0)\n    data['user'].x = torch.tensor(customers['customer_mapped_id'].values, dtype=torch.long)\n    data['product'].x = torch.zeros(len(articles), dtype=torch.float32)\n    data['product'].price = torch.tensor(articles.price.values, dtype=torch.float32).unsqueeze(1)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:00.116071Z","iopub.execute_input":"2025-04-03T19:26:00.116357Z","iopub.status.idle":"2025-04-03T19:26:00.121947Z","shell.execute_reply.started":"2025-04-03T19:26:00.116336Z","shell.execute_reply":"2025-04-03T19:26:00.120987Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# --------------------------\n# 4. Model Architecture\n# --------------------------\nfrom torch_geometric.nn import HGTConv\n\nclass MultiModalGNN(nn.Module):\n    def __init__(self, metadata, num_users, num_products):\n        super(MultiModalGNN, self).__init__()\n        self.user_emb = nn.Embedding(num_users, config.emb_dim)\n        # Product feature layers (used to combine raw features)\n        self.img_fc = nn.Linear(1000, config.emb_dim)\n        self.txt_fc = nn.Linear(768, config.emb_dim)\n        self.price_encoder = nn.Sequential(\n            nn.Linear(1, 64),\n            nn.ReLU(),\n            nn.Linear(64, config.emb_dim)\n        )\n        self.conv1 = HGTConv(config.emb_dim, config.emb_dim, metadata, heads=config.num_heads)\n        self.conv2 = HGTConv(config.emb_dim, config.emb_dim, metadata, heads=config.num_heads)\n        self.dropout = nn.Dropout(config.dropout)\n\n    def forward(self, x_dict, edge_index_dict):\n        user_ids = x_dict['user'].to(device)\n        x_dict['user'] = self.user_emb(user_ids)\n        x_dict = self.conv1(x_dict, edge_index_dict)\n        x_dict = {k: F.gelu(v) for k, v in x_dict.items()}\n        x_dict = {k: self.dropout(v) for k, v in x_dict.items()}\n        x_dict = self.conv2(x_dict, edge_index_dict)\n        return x_dict\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:03.348633Z","iopub.execute_input":"2025-04-03T19:26:03.349066Z","iopub.status.idle":"2025-04-03T19:26:03.358651Z","shell.execute_reply.started":"2025-04-03T19:26:03.349028Z","shell.execute_reply":"2025-04-03T19:26:03.357628Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# --------------------------\n# 5. Data Splitting\n# --------------------------\ndef create_splits(transactions):\n    splitter = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n    train_idx, test_idx = next(splitter.split(transactions, groups=transactions['customer_mapped_id']))\n    train_trans = transactions.iloc[train_idx]\n    temp_trans = transactions.iloc[test_idx]\n    splitter = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n    val_idx, test_idx = next(splitter.split(temp_trans, groups=temp_trans['customer_mapped_id']))\n    return train_trans, temp_trans.iloc[val_idx], temp_trans.iloc[test_idx]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:06.637161Z","iopub.execute_input":"2025-04-03T19:26:06.637466Z","iopub.status.idle":"2025-04-03T19:26:06.642223Z","shell.execute_reply.started":"2025-04-03T19:26:06.637442Z","shell.execute_reply":"2025-04-03T19:26:06.641152Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# --------------------------\n# 6. Custom Neighbor Loader (unchanged)\n# --------------------------\ndef sample_neighbors(data: HeteroData, edge_type: tuple, src_nodes: torch.Tensor, num_samples: int) -> torch.Tensor:\n    edge_index = data[edge_type].edge_index\n    src = edge_index[0]\n    tgt = edge_index[1]\n    sampled_list = []\n    for node in src_nodes.tolist():\n        mask = (src == node)\n        candidates = tgt[mask]\n        if candidates.numel() == 0:\n            continue\n        if candidates.numel() > num_samples:\n            perm = torch.randperm(candidates.numel())[:num_samples]\n            sampled = candidates[perm]\n        else:\n            sampled = candidates\n        sampled_list.append(sampled)\n    if sampled_list:\n        sampled_tgts = torch.cat(sampled_list)\n    else:\n        sampled_tgts = torch.tensor([], dtype=torch.long)\n    return torch.unique(sampled_tgts)\n\nclass CustomNeighborLoader:\n    def __init__(self, data: HeteroData, input_nodes: tuple, batch_size: int,\n                 num_neighbors: dict, shuffle: bool = True):\n        self.data = data\n        self.input_nodes = input_nodes\n        self.batch_size = batch_size\n        self.num_neighbors = num_neighbors\n        self.shuffle = shuffle\n        self.node_type = input_nodes[0]\n        self.node_indices = input_nodes[1]\n        if self.shuffle:\n            self.node_indices = self.node_indices[torch.randperm(self.node_indices.size(0))]\n        self.num_batches = math.ceil(self.node_indices.size(0) / batch_size)\n    \n    def __len__(self):\n        return self.num_batches\n    \n    def __iter__(self):\n        for i in range(self.num_batches):\n            batch_seed = self.node_indices[i * self.batch_size: (i+1) * self.batch_size]\n            n1 = self.num_neighbors.get(('user', 'buys', 'product'), [0])[0]\n            sampled_products = sample_neighbors(self.data, ('user', 'buys', 'product'), batch_seed, n1)\n            n2 = self.num_neighbors.get(('product', 'rev_buys', 'user'), [0])[0]\n            sampled_users_hop2 = sample_neighbors(self.data, ('product', 'rev_buys', 'user'), sampled_products, n2)\n            final_users = torch.unique(torch.cat([batch_seed, sampled_users_hop2]))\n            final_products = sampled_products\n            sub_data = HeteroData()\n            sorted_users, _ = torch.sort(final_users)\n            user_map = {int(u.item()): i for i, u in enumerate(sorted_users)}\n            sub_data['user'].num_nodes = sorted_users.size(0)\n            sub_data['user'].x = sorted_users.clone().to(torch.long)\n            sorted_products, _ = torch.sort(final_products)\n            prod_map = {int(p.item()): i for i, p in enumerate(sorted_products)}\n            sub_data['product'].num_nodes = sorted_products.size(0)\n            sub_data['product'].x = torch.zeros(len(sorted_products), dtype=torch.float32)\n            edge_index = self.data['user', 'buys', 'product'].edge_index\n            mask = (torch.isin(edge_index[0], sorted_users) & torch.isin(edge_index[1], sorted_products))\n            sub_edge_index = edge_index[:, mask].clone()\n            for j in range(sub_edge_index.size(1)):\n                src = int(sub_edge_index[0, j].item())\n                tgt = int(sub_edge_index[1, j].item())\n                sub_edge_index[0, j] = user_map[src]\n                sub_edge_index[1, j] = prod_map[tgt]\n            sub_data['user', 'buys', 'product'].edge_index = sub_edge_index\n            edge_index = self.data['product', 'rev_buys', 'user'].edge_index\n            mask = (torch.isin(edge_index[0], sorted_products) & torch.isin(edge_index[1], sorted_users))\n            sub_edge_index = edge_index[:, mask].clone()\n            for j in range(sub_edge_index.size(1)):\n                src = int(sub_edge_index[0, j].item())\n                tgt = int(sub_edge_index[1, j].item())\n                sub_edge_index[0, j] = prod_map[src]\n                sub_edge_index[1, j] = user_map[tgt]\n            sub_data['product', 'rev_buys', 'user'].edge_index = sub_edge_index\n            seed_mask = torch.zeros(sorted_users.size(0), dtype=torch.bool)\n            for u in batch_seed.tolist():\n                if u in user_map:\n                    seed_mask[user_map[u]] = True\n            sub_data['user'].seed_mask = seed_mask\n            yield sub_data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:19.056062Z","iopub.execute_input":"2025-04-03T19:26:19.056360Z","iopub.status.idle":"2025-04-03T19:26:19.070496Z","shell.execute_reply.started":"2025-04-03T19:26:19.056337Z","shell.execute_reply":"2025-04-03T19:26:19.069606Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# --------------------------\n# 7. Training & Evaluation with Improvements\n# --------------------------\ndef train(model, train_data, val_data, optimizer, articles, prod_feature_dict, save_path='best_model.pth'):\n    best_ndcg = -1\n    scaler = torch.cuda.amp.GradScaler()\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n    epochs_no_improve = 0\n    for epoch in range(config.epochs):\n        model.train()\n        epoch_loss = 0\n        loader = CustomNeighborLoader(\n            data=train_data,\n            input_nodes=('user', torch.arange(train_data['user'].num_nodes, device='cpu')),\n            batch_size=config.batch_size,\n            num_neighbors={('user', 'buys', 'product'): [10],\n                           ('product', 'rev_buys', 'user'): [5]},\n            shuffle=True\n        )\n        print(f\"\\nStarting epoch {epoch+1}\")\n        for batch_idx, batch in enumerate(loader):\n            # print(f\"Processing batch {batch_idx}\")\n            batch = batch.to(device)\n            # Instead of loading product features via DataLoader, we quickly look them up.\n            prod_indices = batch['product'].x.cpu().numpy().astype(int)\n            # Retrieve raw product features from the dictionary and stack them.\n            img_feat_list, txt_feat_list, price_list = [], [], []\n            for pid in prod_indices:\n                feat = prod_feature_dict.get(pid)\n                if feat is None:\n                    continue\n                img_feat_list.append(feat['img_feat'].to(device))\n                txt_feat_list.append(feat['txt_feat'].to(device))\n                price_list.append(feat['price'].to(device))\n            if len(img_feat_list) == 0:\n                print(\"No product features in this batch; skipping.\")\n                continue\n            img_feats = torch.stack(img_feat_list)\n            txt_feats = torch.stack(txt_feat_list)\n            prices = torch.stack(price_list)\n            # Compute product embeddings using the model's product layers\n            img_emb = model.img_fc(img_feats)\n            txt_emb = model.txt_fc(txt_feats)\n            price_emb = model.price_encoder(prices.unsqueeze(1))\n            prod_emb_batch = img_emb + txt_emb + price_emb\n            # Replace the product node features with the precomputed ones\n            batch['product'].x = prod_emb_batch\n            \n            optimizer.zero_grad()\n            with torch.amp.autocast('cuda',enabled=True):\n                out = model(batch.x_dict, batch.edge_index_dict)\n                # Use only the edges in the subgraph for training\n                # pos_edges = batch['user', 'buys', 'product'].edge_index\n                # # Extract user and product embeddings corresponding to these edges\n                # user_edge_emb = out['user'][pos_edges[0]]\n                # prod_edge_emb = out['product'][pos_edges[1]]\n                # # For in-batch negatives, we will form a score matrix from all users and products in the batch\n                # # Here we assume that batch['user'].x and batch['product'].x are in the same order as in out\n                # user_batch_emb = out['user']\n                # prod_batch_emb = out['product']\n                # scores = torch.matmul(user_batch_emb, prod_batch_emb.t())  # [B, B]\n                # pos_scores = scores.diag().unsqueeze(1)  # [B, 1]\n                # # Create a mask to remove diagonal elements (self-positive)\n                # B = scores.size(0)\n                # mask = torch.eye(B, dtype=torch.bool, device=device)\n                # neg_scores = scores.masked_fill(mask, -1e9)\n\n                # Get the positive edge indices (shape: [2, E])\n                pos_edges = batch['user', 'buys', 'product'].edge_index  \n                # Compute positive scores directly for each edge:\n                user_pos = out['user'][pos_edges[0]]\n                prod_pos = out['product'][pos_edges[1]]\n                pos_scores = (user_pos * prod_pos).sum(dim=1)  # shape: [E]\n                \n                # For each positive edge, sample one negative product from the batch\n                num_edges = pos_edges.size(1)\n                neg_indices = torch.randint(0, out['product'].size(0), (num_edges,), device=device)\n                neg_scores = (user_pos * out['product'][neg_indices]).sum(dim=1)\n                \n                # Use margin ranking loss (which encourages pos_scores > neg_scores + margin)\n                margin = 0.2\n                loss = F.margin_ranking_loss(pos_scores, neg_scores, target=torch.ones_like(pos_scores), margin=margin)\n\n            scaler.scale(loss).backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            scaler.step(optimizer)\n            scaler.update()\n            epoch_loss += loss.item()\n        \n        avg_loss = epoch_loss / len(loader)\n        if val_data is not None:\n            ndcg, recall, auc, map12, recall12 = evaluate(model, val_data, articles)\n            print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, NDCG@10={ndcg:.4f}, Recall@10={recall:.4f}, AUC={auc:.4f}, MAP@12={map12:.4f}, Recall@12={recall12:.4f}\")\n            scheduler.step(ndcg)\n            # Early stopping\n            if ndcg > best_ndcg:\n                best_ndcg = ndcg\n                epochs_no_improve = 0\n                torch.save(model.state_dict(), save_path)\n                print(f\"Best model saved at epoch {epoch+1}\")\n            else:\n                epochs_no_improve += 1\n                if epochs_no_improve >= config.patience:\n                    print(\"Early stopping triggered.\")\n                    break\n\n        else:\n            print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f} (No evaluation)\")\n    return best_ndcg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:23.375426Z","iopub.execute_input":"2025-04-03T19:26:23.375726Z","iopub.status.idle":"2025-04-03T19:26:23.387772Z","shell.execute_reply.started":"2025-04-03T19:26:23.375705Z","shell.execute_reply":"2025-04-03T19:26:23.386810Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"in train data load for each fold best modal is overwritting that should not be happen. if validation is none evaluation should not be done. these changes should be done in the above training loop","metadata":{}},{"cell_type":"code","source":"def evaluate(model, val_data, articles):\n    model.eval()\n    scaler = torch.cuda.amp.GradScaler()\n    loader = CustomNeighborLoader(\n        data=val_data,\n        input_nodes=('user', torch.arange(val_data['user'].num_nodes, device='cpu')),\n        batch_size=config.batch_size,\n        num_neighbors={('user', 'buys', 'product'): [10],\n                       ('product', 'rev_buys', 'user'): [5]},\n        shuffle=False\n    )\n    all_ndcgs, all_recalls, all_aucs, all_maps_12, all_recalls_12 = [], [], [], [], []\n    for batch_idx, batch in enumerate(loader):\n        batch = batch.to(device)\n        # Load product features from precomputed dictionary\n        prod_indices = batch['product'].x.cpu().numpy().astype(int)\n        img_feat_list, txt_feat_list, price_list = [], [], []\n        for pid in prod_indices:\n            feat = prod_feature_dict.get(pid)\n            if feat is None:\n                continue\n            img_feat_list.append(feat['img_feat'].to(device))\n            txt_feat_list.append(feat['txt_feat'].to(device))\n            price_list.append(feat['price'].to(device))\n        if len(img_feat_list) == 0:\n            continue\n        img_feats = torch.stack(img_feat_list)\n        txt_feats = torch.stack(txt_feat_list)\n        prices = torch.stack(price_list)\n        img_emb = model.img_fc(img_feats)\n        txt_emb = model.txt_fc(txt_feats)\n        price_emb = model.price_encoder(prices.unsqueeze(1))\n        batch['product'].x = (img_emb + txt_emb + price_emb).to(device)\n        try:\n            with torch.amp.autocast('cuda', enabled=True):\n                out = model(batch.x_dict, batch.edge_index_dict)\n            user_embeddings = out['user'].detach()\n            product_embeddings = out['product'].detach()\n            scores = torch.mm(user_embeddings, product_embeddings.t())\n            pos_edges = batch['user', 'buys', 'product'].edge_index\n            \n            ndcg = calculate_ndcg(scores, pos_edges, k=10)\n            recall = calculate_recall(scores, pos_edges, k=10)\n            auc = calculate_auc(scores, pos_edges)\n            map_12 = calculate_map(scores, pos_edges, k=12)\n            recall_12 = calculate_recall(scores, pos_edges, k=12)\n            all_ndcgs.append(ndcg)\n            all_recalls.append(recall)\n            all_aucs.append(auc)\n            all_maps_12.append(map_12)\n            all_recalls_12.append(recall_12)\n        except Exception as e:\n            print(f\"Error during evaluation of batch {batch_idx+1}: {e}\")\n            continue\n    return (np.mean(all_ndcgs) if all_ndcgs else 0,\n            np.mean(all_recalls) if all_recalls else 0,\n            np.mean(all_aucs) if all_aucs else 0,\n            np.mean(all_maps_12) if all_maps_12 else 0,\n            np.mean(all_recalls_12) if all_recalls_12 else 0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:27.967979Z","iopub.execute_input":"2025-04-03T19:26:27.968291Z","iopub.status.idle":"2025-04-03T19:26:27.977767Z","shell.execute_reply.started":"2025-04-03T19:26:27.968266Z","shell.execute_reply":"2025-04-03T19:26:27.976913Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# --------------------------\n# 8. Metrics (unchanged)\n# --------------------------\ndef calculate_ndcg(scores, edges, k=10):\n    scores = scores.detach().cpu()\n    user_items = {}\n    for u, i in edges.t().tolist():\n        if u not in user_items:\n            user_items[u] = set()\n        user_items[u].add(i)\n    ndcgs = []\n    for u in user_items.keys():\n        relevant_items = user_items[u]\n        if len(relevant_items) == 0:\n            continue\n        user_scores = scores[u]\n        top_k_items = torch.topk(user_scores, k=k).indices.tolist()\n        dcg = sum(1 / np.log2(rank + 2) for rank, item_id in enumerate(top_k_items) if item_id in relevant_items)\n        ideal_dcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant_items), k)))\n        if ideal_dcg > 0:\n            ndcgs.append(dcg / ideal_dcg)\n    return np.mean(ndcgs) if ndcgs else 0.0\n\ndef calculate_recall(scores, edges, k=10):\n    user_items = {}\n    for u, i in edges.t().tolist():\n        user_items.setdefault(u, set()).add(i)\n    recalls = []\n    for u in range(scores.size(0)):\n        pred = set(scores[u].argsort(descending=True)[:k].tolist())\n        rel = user_items.get(u, set())\n        if len(rel) == 0: continue\n        recalls.append(len(pred & rel)/len(rel))\n    return np.mean(recalls) if recalls else 0\n\ndef calculate_auc(scores, edges):\n    pos_pairs = scores[edges[0], edges[1]]\n    neg_pairs = scores[torch.randint(0, scores.size(0), (len(pos_pairs),)),\n                       torch.randint(0, scores.size(1), (len(pos_pairs),))]\n    y_true = torch.cat([torch.ones_like(pos_pairs), torch.zeros_like(neg_pairs)])\n    y_score = torch.cat([pos_pairs.sigmoid(), neg_pairs.sigmoid()])\n    return roc_auc_score(y_true.cpu().numpy(), y_score.cpu().numpy())\n\ndef calculate_map(scores, edges, k=12):\n    user_items = {}\n    for u, i in edges.t().tolist():\n        user_items.setdefault(u, set()).add(i)\n    maps = []\n    for u in range(scores.size(0)):\n        rel = user_items.get(u, set())\n        if not rel: continue\n        pred = scores[u].argsort(descending=True)[:k].tolist()\n        hits, ap = 0, 0\n        for i, item in enumerate(pred):\n            if item in rel:\n                hits += 1\n                ap += hits / (i + 1)\n        maps.append(ap / min(len(rel), k))\n    return np.mean(maps) if maps else 0.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:31.304331Z","iopub.execute_input":"2025-04-03T19:26:31.304629Z","iopub.status.idle":"2025-04-03T19:26:31.315596Z","shell.execute_reply.started":"2025-04-03T19:26:31.304606Z","shell.execute_reply":"2025-04-03T19:26:31.314915Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# --------------------------\n# 9. Cross-Validation (unchanged)\n# --------------------------\ndef cross_validate(articles, customers, transactions):\n    kf = GroupKFold(config.k_folds)\n    users = transactions.customer_mapped_id.unique()\n    metrics = []\n    for fold, (train_idx, val_idx) in enumerate(kf.split(users, groups=users)):\n        print(f\"\\n=== Fold {fold+1} ===\")\n        train_users = users[train_idx]\n        val_users = users[val_idx]\n        fold_train_trans = transactions[transactions.customer_mapped_id.isin(train_users)]\n        fold_val_trans = transactions[transactions.customer_mapped_id.isin(val_users)]\n        fold_customers = customers[customers['customer_mapped_id'].isin(np.concatenate([train_users, val_users]))].copy()\n        fold_article_ids = set(fold_train_trans.article_mapped_id).union(set(fold_val_trans.article_mapped_id))\n        fold_articles = articles[articles.article_mapped_id.isin(fold_article_ids)].copy()\n        train_data = build_graph(fold_train_trans, fold_articles, fold_customers)\n        val_data = build_graph(fold_val_trans, fold_articles, fold_customers)\n        num_users = fold_customers['customer_mapped_id'].max() + 1\n        num_products = fold_articles['article_mapped_id'].max() + 1\n        model = MultiModalGNN(train_data.metadata(), num_users, num_products).to(device)\n        optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n        _ = train(model, train_data, val_data, optimizer, fold_articles, prod_feature_dict, save_path=f\"best_model_fold{fold+1}.pth\")\n        del optimizer\n        torch.cuda.empty_cache() \n    print(f\"\\nCross-validation complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:34.773303Z","iopub.execute_input":"2025-04-03T19:26:34.773669Z","iopub.status.idle":"2025-04-03T19:26:34.780259Z","shell.execute_reply.started":"2025-04-03T19:26:34.773643Z","shell.execute_reply":"2025-04-03T19:26:34.779394Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# import zipfile\nimport pickle\n\n# --------------------------\n# 10. Main Execution: Step-by-Step Approach\n# --------------------------\nif __name__ == \"__main__\":\n    # Step 1: Preprocess data\n    # sampled_customers, transactions, articles = load_and_preprocess()\n    PREPROCESSED_DIR = \"/kaggle/input/preprocessed-data-7/\"\n\n    # Load dataframes\n    articles = pd.read_pickle(os.path.join(PREPROCESSED_DIR, \"articles.pkl\"))\n    customers = pd.read_pickle(os.path.join(PREPROCESSED_DIR, \"customers.pkl\"))\n    transactions = pd.read_pickle(os.path.join(PREPROCESSED_DIR, \"transactions.pkl\"))\n    \n    print(f\"Articles: {len(articles)}, Customers: {len(customers)}, Transactions: {len(transactions)}\")\n    \n    # Make this dictionary globally accessible for evaluate() and train()\n    global prod_feature_dict\n\n    with open(\"/kaggle/input/prod-feature-dict/prod_feature_dict.pkl\", \"rb\") as f:\n        prod_feature_dict = pickle.load(f)\n\n    # Step 2: Build product feature dictionary from precomputed features\n    # prod_feature_dict = build_product_feature_dict(articles)\n    # # Define a directory to save preprocessed files\n    # PROD_FEATUREDICT_DIR = \"/kaggle/working/prod_feature_dict\"\n    # ZIP_FILE = \"/kaggle/working/prod_feature_dict.zip\"\n    # os.makedirs(PROD_FEATUREDICT_DIR, exist_ok=True)\n    \n    # # Save dataframes (articles, customers, transactions)\n    # with open(os.path.join(PROD_FEATUREDICT_DIR, \"prod_feature_dict.pkl\"), 'wb') as f:\n    #     pickle.dump(prod_feature_dict, f)\n    \n    # # ‚úÖ Create a ZIP archive containing all preprocessed files\n    # with zipfile.ZipFile(ZIP_FILE, 'w') as zipf:\n    #     for file in os.listdir(PROD_FEATUREDICT_DIR):\n    #         zipf.write(os.path.join(PROD_FEATUREDICT_DIR, file), arcname=file)\n    \n    # print(f\"‚úÖ MULTI completed! Saved as {ZIP_FILE}\")\n    \n    # Step 3: Create train/val/test splits\n    train_trans, val_trans, test_trans = create_splits(transactions)\n    # Step 5: Build graphs for train, validation, and test splits\n    # train_data = build_graph(train_trans, articles, customers)\n    # val_data   = build_graph(val_trans, articles, customers)\n    test_data  = build_graph(test_trans, articles, customers)\n    # Step 4: Cross-validate on training subset (optional)\n    print(\"Starting cross-validation on training data...\")\n    cross_validate(articles, customers, train_trans)\n    print(\"Cross-validation complete.\")\n    \n    # ‚úÖ Step A: Combine train + val transactions\n    trainval_trans = pd.concat([train_trans, val_trans], ignore_index=True)\n    \n    # ‚úÖ Step B: Rebuild graph using train + val data\n    trainval_data = build_graph(trainval_trans, articles, customers)\n    \n    # ‚úÖ Step C: Initialize model with same architecture\n    model = MultiModalGNN(trainval_data.metadata(), customers['customer_mapped_id'].max() + 1, articles['article_mapped_id'].max() + 1).to(device)\n    \n    # # ‚úÖ Step D: Load best weights from CV\n    # model.load_state_dict(torch.load(\"best_model.pth\"))\n    # print(\"‚úÖ Loaded best model from CV.\")\n    \n    # # ‚úÖ Step E: Reinitialize optimizer (for retraining)\n    # optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n    \n    # # ‚úÖ Step F: Retrain model on train + val (no val_data used now)\n    # print(\"\\nüîÅ Retraining on Train + Validation set...\")\n    # best_ndcg = train(model, trainval_data, val_data=None, optimizer=optimizer, articles=articles, prod_feature_dict=prod_feature_dict)\n    # print(\"best_ndcg\", best_ndcg)\n    # # ‚úÖ Step G: Evaluate on the test set\n    # print(\"\\nüß™ Final Evaluation on Test Set\")\n    # ndcg, recall, auc, map12, recall12 = evaluate(model, test_data, articles)\n    # print(f\"\\n‚úÖ Final Test Performance:\")\n    # print(f\"NDCG@10: {ndcg:.4f}\")\n    # print(f\"Recall@10: {recall:.4f}\")\n    # print(f\"AUC: {auc:.4f}\")\n    # print(f\"MAP@12: {map12:.4f}\")\n    # print(f\"Recall@12: {recall12:.4f}\")\n    \n    # # ‚úÖ Step H: Save the retrained final model\n    # torch.save({\n    #     'state_dict': model.state_dict(),\n    #     'metadata': trainval_data.metadata(),\n    #     'config': config.__dict__\n    # }, \"final_model_retrained.pth\")\n    # print(\"‚úÖ Retrained model saved as final_model_retrained.pth\")\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-31T04:43:53.244292Z","iopub.execute_input":"2025-03-31T04:43:53.244624Z","iopub.status.idle":"2025-03-31T13:52:26.457951Z","shell.execute_reply.started":"2025-03-31T04:43:53.244599Z","shell.execute_reply":"2025-03-31T13:52:26.457255Z"}},"outputs":[{"name":"stdout","text":"Articles: 80654, Customers: 88647, Transactions: 2092109\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-12-bbf0993fa120>:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  edge_index = torch.tensor([\n","output_type":"stream"},{"name":"stdout","text":"Starting cross-validation on training data...\n\n=== Fold 1 ===\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-17-efcb8dbd882e>:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"\nStarting epoch 1\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Error during evaluation of batch 433: selected index k out of range\nEpoch 1: Loss=0.0738, NDCG@10=0.0214, Recall@10=0.0403, AUC=0.5322, MAP@12=0.0123, Recall@12=0.0493\nBest model saved at epoch 1\n\nStarting epoch 2\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Loss=0.0340, NDCG@10=0.0290, Recall@10=0.0532, AUC=0.5728, MAP@12=0.0166, Recall@12=0.0640\nBest model saved at epoch 2\n\nStarting epoch 3\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Loss=0.0237, NDCG@10=0.0316, Recall@10=0.0573, AUC=0.5799, MAP@12=0.0181, Recall@12=0.0687\nBest model saved at epoch 3\n\nStarting epoch 4\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Loss=0.0205, NDCG@10=0.0326, Recall@10=0.0586, AUC=0.5850, MAP@12=0.0188, Recall@12=0.0700\nBest model saved at epoch 4\n\nStarting epoch 5\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Loss=0.0190, NDCG@10=0.0326, Recall@10=0.0590, AUC=0.5900, MAP@12=0.0187, Recall@12=0.0705\n\nStarting epoch 6\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Loss=0.0179, NDCG@10=0.0336, Recall@10=0.0604, AUC=0.5920, MAP@12=0.0193, Recall@12=0.0722\nBest model saved at epoch 6\n\nStarting epoch 7\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Loss=0.0177, NDCG@10=0.0331, Recall@10=0.0594, AUC=0.5943, MAP@12=0.0190, Recall@12=0.0713\n\nStarting epoch 8\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Loss=0.0170, NDCG@10=0.0334, Recall@10=0.0602, AUC=0.5937, MAP@12=0.0191, Recall@12=0.0720\n\nStarting epoch 9\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Loss=0.0164, NDCG@10=0.0341, Recall@10=0.0612, AUC=0.5972, MAP@12=0.0194, Recall@12=0.0732\nBest model saved at epoch 9\n\nStarting epoch 10\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Loss=0.0158, NDCG@10=0.0337, Recall@10=0.0604, AUC=0.6000, MAP@12=0.0192, Recall@12=0.0726\n\nStarting epoch 11\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Loss=0.0155, NDCG@10=0.0344, Recall@10=0.0615, AUC=0.6005, MAP@12=0.0196, Recall@12=0.0740\nBest model saved at epoch 11\n\nStarting epoch 12\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Loss=0.0152, NDCG@10=0.0345, Recall@10=0.0613, AUC=0.6007, MAP@12=0.0199, Recall@12=0.0741\nBest model saved at epoch 12\n\nStarting epoch 13\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Loss=0.0149, NDCG@10=0.0355, Recall@10=0.0636, AUC=0.6022, MAP@12=0.0201, Recall@12=0.0761\nBest model saved at epoch 13\n\nStarting epoch 14\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Loss=0.0146, NDCG@10=0.0354, Recall@10=0.0629, AUC=0.6017, MAP@12=0.0202, Recall@12=0.0754\n\nStarting epoch 15\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Loss=0.0144, NDCG@10=0.0358, Recall@10=0.0635, AUC=0.6025, MAP@12=0.0205, Recall@12=0.0760\nBest model saved at epoch 15\n\nStarting epoch 16\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Loss=0.0143, NDCG@10=0.0356, Recall@10=0.0634, AUC=0.6027, MAP@12=0.0203, Recall@12=0.0758\n\nStarting epoch 17\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Loss=0.0139, NDCG@10=0.0362, Recall@10=0.0645, AUC=0.6039, MAP@12=0.0206, Recall@12=0.0771\nBest model saved at epoch 17\n\nStarting epoch 18\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Loss=0.0136, NDCG@10=0.0359, Recall@10=0.0644, AUC=0.6042, MAP@12=0.0203, Recall@12=0.0768\n\nStarting epoch 19\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Loss=0.0135, NDCG@10=0.0367, Recall@10=0.0652, AUC=0.6058, MAP@12=0.0208, Recall@12=0.0777\nBest model saved at epoch 19\n\nStarting epoch 20\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Error during evaluation of batch 433: selected index k out of range\nEpoch 20: Loss=0.0134, NDCG@10=0.0355, Recall@10=0.0633, AUC=0.6048, MAP@12=0.0199, Recall@12=0.0759\n\nStarting epoch 21\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Loss=0.0134, NDCG@10=0.0365, Recall@10=0.0653, AUC=0.6051, MAP@12=0.0207, Recall@12=0.0782\n\nStarting epoch 22\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22: Loss=0.0132, NDCG@10=0.0372, Recall@10=0.0662, AUC=0.6066, MAP@12=0.0210, Recall@12=0.0787\nBest model saved at epoch 22\n\n=== Fold 2 ===\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-17-efcb8dbd882e>:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"\nStarting epoch 1\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Loss=0.0671, NDCG@10=0.0225, Recall@10=0.0427, AUC=0.4950, MAP@12=0.0129, Recall@12=0.0519\nBest model saved at epoch 1\n\nStarting epoch 2\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Loss=0.0361, NDCG@10=0.0259, Recall@10=0.0480, AUC=0.5230, MAP@12=0.0149, Recall@12=0.0580\nBest model saved at epoch 2\n\nStarting epoch 3\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Loss=0.0245, NDCG@10=0.0295, Recall@10=0.0535, AUC=0.5678, MAP@12=0.0169, Recall@12=0.0645\nBest model saved at epoch 3\n\nStarting epoch 4\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Loss=0.0213, NDCG@10=0.0331, Recall@10=0.0587, AUC=0.5704, MAP@12=0.0188, Recall@12=0.0706\nBest model saved at epoch 4\n\nStarting epoch 5\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Loss=0.0201, NDCG@10=0.0352, Recall@10=0.0626, AUC=0.5754, MAP@12=0.0199, Recall@12=0.0751\nBest model saved at epoch 5\n\nStarting epoch 6\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Loss=0.0193, NDCG@10=0.0364, Recall@10=0.0638, AUC=0.5782, MAP@12=0.0206, Recall@12=0.0767\nBest model saved at epoch 6\n\nStarting epoch 7\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Loss=0.0187, NDCG@10=0.0371, Recall@10=0.0651, AUC=0.5801, MAP@12=0.0209, Recall@12=0.0785\nBest model saved at epoch 7\n\nStarting epoch 8\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Loss=0.0182, NDCG@10=0.0375, Recall@10=0.0659, AUC=0.5842, MAP@12=0.0212, Recall@12=0.0793\nBest model saved at epoch 8\n\nStarting epoch 9\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Loss=0.0172, NDCG@10=0.0393, Recall@10=0.0685, AUC=0.5842, MAP@12=0.0222, Recall@12=0.0819\nBest model saved at epoch 9\n\nStarting epoch 10\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Loss=0.0168, NDCG@10=0.0402, Recall@10=0.0699, AUC=0.5876, MAP@12=0.0226, Recall@12=0.0837\nBest model saved at epoch 10\n\nStarting epoch 11\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Loss=0.0166, NDCG@10=0.0407, Recall@10=0.0710, AUC=0.5891, MAP@12=0.0228, Recall@12=0.0847\nBest model saved at epoch 11\n\nStarting epoch 12\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Loss=0.0165, NDCG@10=0.0415, Recall@10=0.0717, AUC=0.5908, MAP@12=0.0234, Recall@12=0.0855\nBest model saved at epoch 12\n\nStarting epoch 13\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Loss=0.0163, NDCG@10=0.0419, Recall@10=0.0722, AUC=0.5895, MAP@12=0.0236, Recall@12=0.0858\nBest model saved at epoch 13\n\nStarting epoch 14\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Loss=0.0159, NDCG@10=0.0425, Recall@10=0.0730, AUC=0.5930, MAP@12=0.0239, Recall@12=0.0872\nBest model saved at epoch 14\n\nStarting epoch 15\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Loss=0.0158, NDCG@10=0.0434, Recall@10=0.0744, AUC=0.5933, MAP@12=0.0244, Recall@12=0.0885\nBest model saved at epoch 15\n\nStarting epoch 16\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Loss=0.0156, NDCG@10=0.0428, Recall@10=0.0735, AUC=0.5934, MAP@12=0.0241, Recall@12=0.0877\n\nStarting epoch 17\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Loss=0.0158, NDCG@10=0.0437, Recall@10=0.0747, AUC=0.5952, MAP@12=0.0246, Recall@12=0.0886\nBest model saved at epoch 17\n\nStarting epoch 18\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Loss=0.0154, NDCG@10=0.0429, Recall@10=0.0734, AUC=0.5945, MAP@12=0.0242, Recall@12=0.0877\n\nStarting epoch 19\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Loss=0.0157, NDCG@10=0.0435, Recall@10=0.0747, AUC=0.5973, MAP@12=0.0244, Recall@12=0.0893\n\nStarting epoch 20\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Loss=0.0150, NDCG@10=0.0441, Recall@10=0.0753, AUC=0.5971, MAP@12=0.0248, Recall@12=0.0896\nBest model saved at epoch 20\n\nStarting epoch 21\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Loss=0.0153, NDCG@10=0.0444, Recall@10=0.0758, AUC=0.5964, MAP@12=0.0249, Recall@12=0.0902\nBest model saved at epoch 21\n\nStarting epoch 22\nNo product features in this batch; skipping.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22: Loss=0.0147, NDCG@10=0.0442, Recall@10=0.0752, AUC=0.5973, MAP@12=0.0248, Recall@12=0.0894\n\nCross-validation complete.\nCross-validation complete.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"fold1\nEpoch 22: Loss=0.0132, NDCG@10=0.0372, Recall@10=0.0662, AUC=0.6066, MAP@12=0.0210, Recall@12=0.0787\nBest model saved at epoch 22\nfold 2\nEpoch 22: Loss=0.0147, NDCG@10=0.0442, Recall@10=0.0752, AUC=0.5973, MAP@12=0.0248, Recall@12=0.0894\n","metadata":{}},{"cell_type":"code","source":"import pickle\n\n# # ‚úÖ Step A: Combine train + val transactions\n# trainval_trans = pd.concat([train_trans, val_trans], ignore_index=True)\n\n# # ‚úÖ Step B: Rebuild graph using train + val data\n# trainval_data = build_graph(trainval_trans, articles, customers)\n\n# # ‚úÖ Step C: Initialize model with same architecture\n# model = MultiModalGNN(trainval_data.metadata(), customers['customer_mapped_id'].max() + 1, articles['article_mapped_id'].max() + 1).to(device)\n\n# # ‚úÖ Step D: Load best weights from CV\n# model.load_state_dict(torch.load(\"best_model.pth\"))\n# print(\"‚úÖ Loaded best model from CV.\")\n\n# # ‚úÖ Step E: Reinitialize optimizer (for retraining)\n# optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n\n# # ‚úÖ Step F: Retrain model on train + val (no val_data used now)\n# print(\"\\nüîÅ Retraining on Train + Validation set...\")\n# best_ndcg = train(model, trainval_data, val_data=None, optimizer=optimizer, articles=articles, prod_feature_dict=prod_feature_dict)\n# test_data  = build_graph(test_trans, articles, customers)\n# # ‚úÖ Step G: Evaluate on the test set\n# print(\"\\nüß™ Final Evaluation on Test Set\")\n# ndcg, recall, auc = evaluate(model, test_data, articles)\n# print(f\"\\n‚úÖ Final Test Performance:\")\n# print(f\"NDCG@10: {ndcg:.4f}\")\n# print(f\"Recall@10: {recall:.4f}\")\n# print(f\"AUC: {auc:.4f}\")\n\n# # ‚úÖ Step H: Save the retrained final model\n# torch.save({\n#     'state_dict': model.state_dict(),\n#     'metadata': trainval_data.metadata(),\n#     'config': config.__dict__\n# }, \"final_model_retrained.pth\")\n# print(\"‚úÖ Retrained model saved as final_model_retrained.pth\")\nPREPROCESSED_DIR = \"/kaggle/input/preprocessed-data-7/\"\n\n# Load dataframes\narticles = pd.read_pickle(os.path.join(PREPROCESSED_DIR, \"articles.pkl\"))\ncustomers = pd.read_pickle(os.path.join(PREPROCESSED_DIR, \"customers.pkl\"))\ntransactions = pd.read_pickle(os.path.join(PREPROCESSED_DIR, \"transactions.pkl\"))\n\nprint(f\"Articles: {len(articles)}, Customers: {len(customers)}, Transactions: {len(transactions)}\")\n\n# Make this dictionary globally accessible for evaluate() and train()\nglobal prod_feature_dict\n\nwith open(\"/kaggle/input/prod-feature-dict/prod_feature_dict.pkl\", \"rb\") as f:\n    prod_feature_dict = pickle.load(f)\n\ntrain_trans, val_trans, test_trans = create_splits(transactions)\n\ntest_data  = build_graph(test_trans, articles, customers)\n\n\n# ‚úÖ Step A: Combine train + val transactions\ntrainval_trans = pd.concat([train_trans, val_trans], ignore_index=True)\n\n# ‚úÖ Step B: Rebuild graph using train + val data\ntrainval_data = build_graph(trainval_trans, articles, customers)\n\n# Load the checkpoint\ncheckpoint = torch.load(\"/kaggle/input/not-cold-start-halfly-trained/other/default/1/best_model (1).pth\", weights_only=True)\nstate_dict = checkpoint\nmodel = MultiModalGNN(trainval_data.metadata(), customers['customer_mapped_id'].max() + 1, articles['article_mapped_id'].max() + 1).to(device)\n\n# Get the checkpoint user embeddings and current model's user embeddings\nold_user_emb = state_dict[\"user_emb.weight\"]   # Shape: [55299, 256]\nnew_user_emb = model.user_emb.weight             # Shape: [88647, 256]\n\n# Check how many rows to copy\nnum_overlap = old_user_emb.size(0)\n\n# Replace the first num_overlap rows of the new model's embedding with the loaded weights\nnew_user_emb.data[:num_overlap] = old_user_emb\n\n# Optionally, leave the remaining rows as is (randomly initialized) or initialize them as desired\nstate_dict[\"user_emb.weight\"] = new_user_emb\n\n# Now load state_dict with strict=False to avoid errors on the rest of the mismatched keys\nmodel.load_state_dict(state_dict, strict=False)\n\nprint(\"‚úÖ Loaded best model from CV.\")\n\n\n# ‚úÖ Step E: Reinitialize optimizer (for retraining)\noptimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n\n# ‚úÖ Step F: Retrain model on train + val (no val_data used now)\nprint(\"\\nüîÅ Retraining on Train + Validation set...\")\nbest_ndcg = train(model, trainval_data, val_data=None, optimizer=optimizer, articles=articles, prod_feature_dict=prod_feature_dict)\nprint(\"best_ndcg\", best_ndcg)\n# ‚úÖ Step G: Evaluate on the test set\nprint(\"\\nüß™ Final Evaluation on Test Set\")\nndcg, recall, auc, map12, recall12 = evaluate(model, test_data, articles)\nprint(f\"\\n‚úÖ Final Test Performance:\")\nprint(f\"NDCG@10: {ndcg:.4f}\")\nprint(f\"Recall@10: {recall:.4f}\")\nprint(f\"AUC: {auc:.4f}\")\nprint(f\"MAP@12: {map12:.4f}\")\nprint(f\"Recall@12: {recall12:.4f}\")\n\n# ‚úÖ Step H: Save the retrained final model\ntorch.save({\n    'state_dict': model.state_dict(),\n    'metadata': trainval_data.metadata(),\n    'config': config.__dict__\n}, \"final_model_retrained.pth\")\nprint(\"‚úÖ Retrained model saved as final_model_retrained.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:49.370305Z","iopub.execute_input":"2025-04-03T19:26:49.370634Z","iopub.status.idle":"2025-04-03T20:40:44.513542Z","shell.execute_reply.started":"2025-04-03T19:26:49.370611Z","shell.execute_reply":"2025-04-03T20:40:44.512603Z"}},"outputs":[{"name":"stdout","text":"Articles: 80654, Customers: 88647, Transactions: 2092109\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-11-bbf0993fa120>:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  edge_index = torch.tensor([\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Loaded best model from CV.\n\nüîÅ Retraining on Train + Validation set...\n\nStarting epoch 1\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-16-efcb8dbd882e>:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Loss=0.0199 (No evaluation)\n\nStarting epoch 2\nEpoch 2: Loss=0.0196 (No evaluation)\nbest_ndcg -1\n\nüß™ Final Evaluation on Test Set\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-17-55f316d8f40e>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Final Test Performance:\nNDCG@10: 0.1006\nRecall@10: 0.1783\nAUC: 0.7079\nMAP@12: 0.0648\nRecall@12: 0.2076\n‚úÖ Retrained model saved as final_model_retrained.pth\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"emd dim 256\n\nfold 1\nEpoch 1: Loss=0.0754, NDCG=0.0356, Recall=0.0688, AUC=0.5062\nEpoch 2: Loss=0.0386, NDCG=0.0432, Recall=0.0816, AUC=0.5930\nEpoch 3: Loss=0.0268, NDCG=0.0499, Recall=0.0926, AUC=0.6063\nfold 2\nEpoch 1: Loss=0.0758, NDCG=0.0349, Recall=0.0681, AUC=0.4909\nEpoch 2: Loss=0.0350, NDCG=0.0431, Recall=0.0818, AUC=0.6007\nEpoch 3: Loss=0.0264, NDCG=0.0481, Recall=0.0894, AUC=0.6121\nfold 3\nEpoch 1: Loss=0.0750, NDCG=0.0333, Recall=0.0654, AUC=0.5014\nEpoch 2: Loss=0.0350, NDCG=0.0423, Recall=0.0803, AUC=0.5975\nEpoch 3: Loss=0.0254, NDCG=0.0467, Recall=0.0878, AUC=0.6083\n\n\nFinal Test Performance:\nNDCG@10: 0.0817\nRecall@10: 0.1535\nAUC: 0.6685","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T08:01:01.030833Z","iopub.status.idle":"2025-03-30T08:01:01.031118Z","shell.execute_reply":"2025-03-30T08:01:01.031006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"em dim 384\nfold 1\nEpoch 1: Loss=0.1663, NDCG@10=0.0101, Recall@10=0.0190, AUC=0.4867, MAP@12=0.0059, Recall@12=0.0211","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T08:01:01.031715Z","iopub.status.idle":"2025-03-30T08:01:01.031983Z","shell.execute_reply":"2025-03-30T08:01:01.031878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"em dim 128\nfold 1\nEpoch 1: Loss=0.1755, NDCG@10=0.0036, Recall@10=0.0066, AUC=0.4642, MAP@12=0.0018, Recall@12=0.0084","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T08:01:01.032966Z","iopub.status.idle":"2025-03-30T08:01:01.033303Z","shell.execute_reply":"2025-03-30T08:01:01.033147Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 128\nemb_dim = 256\nfinal training\nfold 1\nEpoch 1: Loss=0.0772, NDCG@10=0.0341, Recall@10=0.0658, AUC=0.4826, MAP@12=0.0205, Recall@12=0.0796\nEpoch 2: Loss=0.0338, NDCG@10=0.0431, Recall@10=0.0815, AUC=0.5986, MAP@12=0.0258, Recall@12=0.0977\nEpoch 3: Loss=0.0258, NDCG@10=0.0470, Recall@10=0.0882, AUC=0.6086, MAP@12=0.0281, Recall@12=0.1056\nEpoch 4: Loss=0.0229, NDCG@10=0.0510, Recall@10=0.0937, AUC=0.6146, MAP@12=0.0307, Recall@12=0.1120\nEpoch 5: Loss=0.0210, NDCG@10=0.0544, Recall@10=0.0986, AUC=0.6199, MAP@12=0.0326, Recall@12=0.1170\nEpoch 6: Loss=0.0202, NDCG@10=0.0549, Recall@10=0.0996, AUC=0.6202, MAP@12=0.0330, Recall@12=0.1186","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"22","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}